{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418eeb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Author: Roufa\n",
    "'''\n",
    "input: \"pdf file\n",
    "output: \"returning bboxes of not matched chapter openers.\n",
    "\n",
    "we are extracting chapter contents, \n",
    "chapter openers and comparing them, returning bboxes of missing chapter openers.\n",
    "'''\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/copy_assessment_tool/modules_final')\n",
    "\n",
    "import re\n",
    "import pdfplumber\n",
    "from fuzzywuzzy import fuzz\n",
    "import spacy\n",
    "from copy_assessment_tool.modules_final.programmatic.TOC.utils import *\n",
    "from json_output import return_json_result\n",
    "\n",
    "\n",
    "\n",
    "def extract_chapters(reader, exclusion_list, exclusion_list_1):\n",
    "    # Extract chapters from the PDF\n",
    "    num_pages = len(reader.pages)\n",
    "    content_page_num, content_page_num_flg = 0, True\n",
    "    chapters, common_text, text_list_compare_prev, content_page_flg, prev_break_flg, cur_break_flg,content_page_cnt_flg,content_page_cnt = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    False,\n",
    "    False,\n",
    "    False,\n",
    "    True,\n",
    "    0\n",
    "    )\n",
    "    for page_num in range(num_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.within_bbox((0, 0, 550, 770)).extract_text_simple()\n",
    "        text_list_compare = re.sub(r\"[^a-zA-Z0-9 .:)\\]\\n]\", \"\", text)\n",
    "        text_list_compare = text_list_compare.split(\"\\n\")\n",
    "        text_list_compare = [\n",
    "            i.strip().lower() for i in text_list_compare if i.strip() != \"\"\n",
    "        ]\n",
    "        # text_list_compare_prev.extend(text_list_compare)\n",
    "\n",
    "        if (len(text_list_compare) > 0) and (((len(text_list_compare[0].split()) < 5)\n",
    "            and (\n",
    "                \"content\" in \"\".join(text_list_compare[0])\n",
    "                or \"index\" in \"\".join(text_list_compare[0])\n",
    "            )\n",
    "        ) or content_page_flg):\n",
    "            if content_page_cnt_flg:\n",
    "                content_page_cnt += 1\n",
    "                \n",
    "            if prev_break_flg:\n",
    "                if (len(text_list_compare[0].split()) < 5) and (\n",
    "                        \"content\" in \"\".join(text_list_compare[0])\n",
    "                        or \"index\" in \"\".join(text_list_compare[0])\n",
    "                  \n",
    "                    \n",
    "                ):\n",
    "                    cur_break_flg = True\n",
    "                    prev_break_flg = False\n",
    "                    content_page_cnt_flg = True\n",
    "                    content_page_cnt = 0\n",
    "                    chapters.clear()\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            content_page_flg = True\n",
    "            chapters.append(text_list_compare)\n",
    "            if content_page_num_flg:\n",
    "                content_page_num = page_num + 1\n",
    "                content_page_num_flg = False\n",
    "            # num = page_num\n",
    "         \n",
    "            for i in [\n",
    "                \"appendix\",\n",
    "                \"bibliography\",\n",
    "                \"index\",\n",
    "                \"list of\",\n",
    "                \"references\",\n",
    "                \"contributors\",\n",
    "            ]:\n",
    "                if ((fuzz.partial_ratio(i, text_list_compare[-1]) > 89) and (len(text_list_compare[-1].split()) < 4)) or (content_page_cnt > 10):\n",
    "                    prev_break_flg = True\n",
    "                    if content_page_cnt > 10:\n",
    "                        content_page_cnt_flg = False\n",
    "                    break\n",
    "            if prev_break_flg and cur_break_flg:\n",
    "                break\n",
    "        elif (len(text_list_compare) == 0) and content_page_flg:\n",
    "            break        \n",
    "    \n",
    "    page_num_line_dict = {}    \n",
    "    if content_page_cnt_flg:\n",
    "        chapters_cp = []\n",
    "        for page_num, ch in enumerate(chapters):\n",
    "            for line_num, line in enumerate(ch):\n",
    "                content_name = \" \".join(line.strip().split())\n",
    "                chapters_cp.append(content_name)\n",
    "                \n",
    "                page_num_line_dict[content_name + \"~\" + str(content_page_num + page_num) + \"~\" + str(line_num+1)] = (content_page_num + page_num, line_num+1)\n",
    "\n",
    "    else:  \n",
    "        num_lines = len(chapters[0])\n",
    "        chapters_cp = []\n",
    "        for page_num, ch in enumerate(chapters):\n",
    "            if len(ch) < 1.25*num_lines:\n",
    "                for line_num, line in enumerate(ch):\n",
    "                    content_name = \" \".join(line.strip().split())\n",
    "                    chapters_cp.append(content_name)\n",
    "\n",
    "                    page_num_line_dict[content_name + \"~\" + str(content_page_num + page_num) + \"~\" + str(line_num+1)] = (content_page_num + page_num, line_num+1)\n",
    "            else:\n",
    "                break\n",
    "    chapters = chapters_cp[1:].copy()\n",
    "    del page_num_line_dict[chapters_cp[0]+\"~\" + str(content_page_num) + \"~\" + str(1)]\n",
    "    \n",
    "    del chapters_cp        \n",
    "    \n",
    "    chapter_next_line_flg, prev_chapter_flg = False, False\n",
    "    # Caters multiline chapter names\n",
    "\n",
    "    for chap in list(page_num_line_dict.keys()):\n",
    "        ch, page_num, line_num = chap.split(\"~\")\n",
    "\n",
    "        chapter_flg, remove_chap = False, True\n",
    "        if (\n",
    "            (\"chapter\" in ch)\n",
    "            or (\"part\" in ch.split()[:2])\n",
    "            or (\"lesson\" in ch.split()[:2])\n",
    "            or (\"introduction\" in ch.split()[:2])\n",
    "        ):\n",
    "            chapter_flg = True\n",
    "            new_ch = (\n",
    "                re.sub(r\"[^a-z]\", \"\", ch).replace(\"chapter\", \"\").replace(\"part\", \"\").strip()\n",
    "            )\n",
    "            if new_ch == \"\":\n",
    "                chapter_next_line_flg = True\n",
    "            else:\n",
    "                prev_chapter_flg = True\n",
    "        else:\n",
    "            search = r\"^[a-z]{1}[ .:)\\]]$\"\n",
    "            alpha_start = re.search(search, ch.split()[0])\n",
    "            if alpha_start:\n",
    "                chapter_flg = True\n",
    "                break\n",
    "            else:\n",
    "                for j in ch.split()[:3]:\n",
    "                    k = re.sub(r\"[^0-9a-z]\", \"\", j)\n",
    "                    num_start = re.search(r\"^[0-9]{1,4}\", k)\n",
    "                    if num_start:\n",
    "                        chapter_flg = True\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                if prev_chapter_flg and not chapter_flg:\n",
    "                    continue\n",
    "\n",
    "        if chapter_flg:\n",
    "            if chapter_next_line_flg:\n",
    "                chap_str = ch\n",
    "                chapters.remove(ch)\n",
    "                del page_num_line_dict[chap]\n",
    "            continue\n",
    "        else:\n",
    "            for j in exclusion_list:\n",
    "                r = fuzz.partial_ratio(ch, j)\n",
    "                if r > 89:\n",
    "                    remove_chap = False\n",
    "                    break\n",
    "            if remove_chap and not chapter_next_line_flg:\n",
    "                # print(\"ch\",ch)\n",
    "                chapters.remove(ch)\n",
    "                del page_num_line_dict[chap]\n",
    "\n",
    "            elif chapter_next_line_flg:\n",
    "                index_val = chapters.index(ch)\n",
    "                chapters.insert(index_val, chap_str + \" \" + ch)\n",
    "                chapters.remove(ch)\n",
    "                del page_num_line_dict[chap]\n",
    "        \n",
    "    chapters_cp = []\n",
    "\n",
    "    \n",
    "    for chap in list(page_num_line_dict.keys()).copy():\n",
    "        ch, page_num, line_num = chap.split(\"~\")\n",
    "\n",
    "        if len(ch.split()) == 1:\n",
    "            if len(re.sub(r\"[0-9]\", \"\", ch)) < 1:\n",
    "                del page_num_line_dict[chap]\n",
    "                continue\n",
    "            else:\n",
    "                chapters_cp.append(ch)\n",
    "\n",
    "        elif len(re.sub(r\"[:)\\]]\", \".\", ch).split(\".\")[0].split()) == 1:\n",
    "            new_ch = (\n",
    "                \" \".join(re.sub(r\"[:)\\]]\", \".\", ch).split(\".\")[1:]).replace(\".\", \"\").strip()\n",
    "            )\n",
    "            chapters_cp.append(new_ch)\n",
    "     \n",
    "            new_ch += \"~\" + page_num + \"~\" + line_num\n",
    "\n",
    "            page_num_line_dict[new_ch] = page_num_line_dict.get(chap)\n",
    "            \n",
    "            del page_num_line_dict[chap]\n",
    "        else:\n",
    "            chapters_cp.append(ch)\n",
    "    chapters = chapters_cp.copy()\n",
    " \n",
    "    \n",
    "    del chapters_cp  \n",
    "    return chapters, page_num_line_dict,page_num\n",
    "\n",
    "\n",
    "def process_df(reader):\n",
    "    chapters_dictionary = {}\n",
    "    exclusion_list = [\n",
    "            \"abbreviations\",\n",
    "            \"appreciations\",\n",
    "            \"acknowledgements\",\n",
    "            \"acknowledgment\"\n",
    "            \"appendix\",\n",
    "            \"authors\",\n",
    "            \"bibliography\",\n",
    "            \"conclusion\",\n",
    "            \"contributors\",\n",
    "            \"documents\",\n",
    "            \"figures\",\n",
    "            \"foreword\",\n",
    "            \"index\",\n",
    "            \"introduction\",\n",
    "            \"list of\",\n",
    "            \"preface\",\n",
    "            \"publication\",\n",
    "            \"references\",\n",
    "            \"synopsis\",\n",
    "            \"tables\",\n",
    "            \"whos who\",\n",
    "        ]\n",
    "    exclusion_list_1 = [\"chapter\", \"part\", \"subject\"]\n",
    "\n",
    "    chapters, page_num_line_dict,page_num = extract_chapters(reader, exclusion_list, exclusion_list_1)\n",
    "\n",
    "   \n",
    "    for key , val in page_num_line_dict.items():\n",
    "        split_key = key.split('~')[0]\n",
    "        chapters_dictionary[split_key] = val\n",
    "    \n",
    "    return chapters,page_num_line_dict,page_num,chapters_dictionary\n",
    "\n",
    "def process_dict(input_dict):\n",
    "    result_dict = {}\n",
    "    for key, value in input_dict.items():\n",
    "        cleaned_key = remove_chapter_or_part_text([key])\n",
    "        cleaned_key = remove_period_colon(cleaned_key)\n",
    "        result_dict[cleaned_key[0]] = value\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def spacy_model_names(new_dictionary):\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    # cleaned = [key for key,val in cleaned_data.items()]\n",
    "    # cleaned\n",
    "    list1=[]\n",
    "    for item in new_dictionary.keys():\n",
    "        doc = nlp(item)\n",
    "        # print(document.ents)\n",
    "        for i in doc.ents:\n",
    "            if i.label_.lower() in [\"person\"]:\n",
    "                list1.append(i)\n",
    "    name_to_remove = [span.text for span in list1]\n",
    "    name_to_remove\n",
    "\n",
    "    new_cleaned_Data = {key: value for key, value in new_dictionary.items() if key not in name_to_remove}\n",
    "    return new_cleaned_Data\n",
    "\n",
    "\n",
    "def filter_boldtext(obj):\n",
    "    # extract bold font \n",
    "    if \"matrix\" in obj.keys():\n",
    "        if \"bold\" in obj[\"fontname\"].lower():\n",
    "            return obj\n",
    "        \n",
    "        \n",
    "def filter_superscript(obj):\n",
    "    # removing superscript in chapter names\n",
    "    if \"matrix\" in obj.keys():\n",
    "        if obj[\"size\"]>8:\n",
    "            return obj\n",
    "\n",
    "\n",
    "def strip_word_in_line(textlines):\n",
    "    new_textlines = []\n",
    "    for text_line in textlines:\n",
    "        text_line = \" \".join([word for word in text_line.split(\" \") if word.strip()])\n",
    "        if text_line:\n",
    "            new_textlines.append(text_line)\n",
    "    return new_textlines\n",
    "\n",
    "def exact_match(pdf,cleaned_chapters,page_num):\n",
    "    # function for exact match in Table of contents against chapter openers\n",
    "    matched_list = {}\n",
    "    \n",
    "    for page_no , page in enumerate(pdf.pages):\n",
    "        if page_no > int(page_num):\n",
    "            text = page.filter(filter_superscript).within_bbox((0, 0, 550, 770)).extract_text_simple()\n",
    "            textlines = text.split(\"\\n\")\n",
    "            \n",
    "            textlines = strip_word_in_line(textlines)\n",
    "            for i , text_line in enumerate(textlines):\n",
    "                text_line = text_line.lower()\n",
    "                \n",
    "                # to remove special symbols\n",
    "                text_line = re.sub(r\"[^a-zA-Z0-9 :\\n]\", \"\", text_line)\n",
    "                text_line = re.sub(r\"[:?]+$ \",\"\",text_line)\n",
    "                text_line = re.sub(r\":(?=\\s|$)\", \"\", text_line)\n",
    "\n",
    "                text_line = remove_chapter_or_part_text([text_line])\n",
    "                text_line = text_line[0]\n",
    "                \n",
    "\n",
    "                for chapter_name,val in cleaned_chapters.items():\n",
    "                    if chapter_name == text_line:\n",
    "                #    if fuzz.ratio(text_line, chapter_name) >= 93:\n",
    "                    ###########################################\n",
    "                    ### EXACT MATCH ########################\n",
    "                    #########################################\n",
    "                    # print(chapter_name)\n",
    "                        matched_list[chapter_name] = val\n",
    "                    \n",
    "                    # if chapter_name == text_line:\n",
    "                       \n",
    "    keys_unique_to_dict1 = set(cleaned_chapters.keys()) - set(matched_list.keys())\n",
    "    unmatched_list = {key: cleaned_chapters[key] for key in keys_unique_to_dict1}\n",
    "                        \n",
    "    # unmatched_list = set(cleaned_chapters) - set(matched_list)         \n",
    "    return matched_list,unmatched_list\n",
    "\n",
    "\n",
    "def merge_text_exact_match(pdf,unmatched_list,page_num):\n",
    "    #### merges two lines exact match \n",
    "    matched_list_merge = {}\n",
    "    \n",
    "    for page_no , page in enumerate(pdf.pages):\n",
    "        if page_no > int(page_num):\n",
    "            text_2 = page.filter(filter_superscript).within_bbox((0, 0, 550, 770)).extract_text_simple()\n",
    "            textlines = text_2.split(\"\\n\")\n",
    "            lines = len(textlines) -1\n",
    "            merge_two_line = [textlines[i]+' '+textlines[i+1] for i in range(lines)]\n",
    "            textlines = strip_word_in_line(merge_two_line)\n",
    "            for text_line in textlines:\n",
    "                text_line = text_line.lower()\n",
    "                \n",
    "                # to remove special symbols\n",
    "                text_line = re.sub(r\"[^a-zA-Z0-9 \\n]\", \"\", text_line)\n",
    "                text_line = re.sub(r\"[:?]+$ \",\"\",text_line)\n",
    "                text_line = re.sub(r\":(?=\\s|$)\", \"\", text_line)\n",
    "                # to remove \"chapter\" and \"part\"\n",
    "                text_line = remove_chapter_or_part_text([text_line])\n",
    "                text_line = text_line[0]\n",
    "                text_line\n",
    "                for chapter_name,val in unmatched_list.items():\n",
    "\n",
    "                    ###########################################\n",
    "                    ### Merged EXACT MATCH ########################\n",
    "                    #########################################\n",
    "                    if chapter_name.lower() == text_line.lower():\n",
    "                        # print(\"March fond\", chapter_name)\n",
    "                        matched_list_merge[chapter_name] = val\n",
    "                        \n",
    "    keys_unique_to_dict2 = set(unmatched_list.keys()) - set(matched_list_merge.keys())\n",
    "    unmatched_list_merge = {key: unmatched_list[key] for key in keys_unique_to_dict2}\n",
    "                        \n",
    "    return matched_list_merge,unmatched_list_merge\n",
    "\n",
    "\n",
    "def bold_text_exact_match(pdf,unmatched_list_merge,page_num):\n",
    "    ######## Bold_text\n",
    "    matched_list_bold = {}\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        if i > int(page_num):\n",
    "            bold_text = page.filter(filter_boldtext).filter(filter_superscript).extract_text() \n",
    "            bold_lines = bold_text.split(\"\\n\")\n",
    "            bold_lines = strip_word_in_line(bold_lines)\n",
    "            for bold_line in bold_lines:\n",
    "                bold_line = bold_line.lower()\n",
    "                \n",
    "                # to remove special symbols\n",
    "                bold_line = re.sub(r\"[^a-zA-Z0-9 \\n]\", \"\", bold_line)\n",
    "                bold_line = re.sub(r\"[:?]+$ \",\"\",bold_line)\n",
    "                bold_line = re.sub(r\":(?=\\s|$)\", \"\", bold_line)\n",
    "                # to remove \"chapter\" and \"part\"\n",
    "                bold_line = remove_chapter_or_part_text([bold_line])\n",
    "                bold_line = bold_line[0]\n",
    "\n",
    "                for chapter_name,val in unmatched_list_merge.items():\n",
    "                    # bold text match\n",
    "                    if bold_line == chapter_name:\n",
    "                        \n",
    "                        matched_list_bold[chapter_name] = val\n",
    "                        \n",
    "    keys_unique_to_dict3 = set(unmatched_list_merge.keys()) - set(matched_list_bold.keys())\n",
    "    unmatched_list_bold = {key: unmatched_list_merge[key] for key in keys_unique_to_dict3}\n",
    "                    \n",
    "    return matched_list_bold ,unmatched_list_bold\n",
    "\n",
    "\n",
    "def fuzzy_match(pdf,unmatched_list_bold,page_num):\n",
    "    matched_fuzzy = {}\n",
    "    for page_no , page in enumerate(pdf.pages): \n",
    "        if page_no > int(page_num):\n",
    "            text = page.filter(filter_superscript).within_bbox((0, 0, 550, 770)).extract_text_simple()\n",
    "            textlines = text.split(\"\\n\")\n",
    "            \n",
    "            textlines = strip_word_in_line(textlines)\n",
    "            for i , text_line in enumerate(textlines):\n",
    "                text_line = text_line.lower()\n",
    "                \n",
    "                # to remove special symbols\n",
    "                text_line = re.sub(r\"[^a-zA-Z0-9 :\\n]\", \"\", text_line)\n",
    "                text_line = re.sub(r\"[:?]+$ \",\"\",text_line)\n",
    "                text_line = re.sub(r\":(?=\\s|$)\", \"\", text_line)\n",
    "                # to remove \"chapter\" and \"part\"\n",
    "                text_line = remove_chapter_or_part_text([text_line])\n",
    "                text_line = text_line[0]\n",
    "                for chapter_names,val in unmatched_list_bold.items():\n",
    "                    # fuzzy match\n",
    "                    if fuzz.ratio(text_line, chapter_names) >=90:\n",
    "              \n",
    "                        matched_fuzzy[chapter_names] = val\n",
    "                        \n",
    "    keys_unique_to_dict4 = set(unmatched_list_bold.keys()) - set(matched_fuzzy.keys())\n",
    "    unmatched_fuzzy = {key: unmatched_list_bold[key] for key in keys_unique_to_dict4}\n",
    "                        \n",
    "                        \n",
    "    return matched_fuzzy,unmatched_fuzzy\n",
    "                                       \n",
    "def extracted_table_of_contents(pdf):\n",
    "\n",
    "    chapters,page_num_line_dict,page_num,chapters_dictionary =process_df(pdf)\n",
    "    result_dict = process_dict(chapters_dictionary)\n",
    "    new_cleaned_Data = spacy_model_names(result_dict)\n",
    "    \n",
    "    matched_list,unmatched_dict = exact_match(pdf,new_cleaned_Data,page_num)\n",
    "    \n",
    "    matched_list_merge,unmatched_dict_merge =merge_text_exact_match(pdf,unmatched_dict,page_num)\n",
    "    matched_list_bold ,unmatched_dict_bold = bold_text_exact_match(pdf,unmatched_dict_merge,page_num)\n",
    "    \n",
    "    matched_fuzzy,unmatched_fuzzy = fuzzy_match(pdf,unmatched_dict_bold,page_num)\n",
    "  \n",
    "                    \n",
    "    return unmatched_fuzzy,matched_fuzzy\n",
    "                                \n",
    "\n",
    "def final_json_results_dumps(path,unmatched_fuzzy):\n",
    "    pdf = pdfplumber.open(path)\n",
    "    final_result = []\n",
    "    for items_k,item_val in unmatched_fuzzy.items():\n",
    "        pg_no =item_val[0]\n",
    "        for i,pages in enumerate(pdf.pages):\n",
    "            if i+1 == pg_no:\n",
    "            \n",
    "                text = pages.extract_text_lines(return_chars=False)\n",
    "                for text_instances in text:\n",
    "                    \n",
    "                    if fuzz.ratio(text_instances['text'], items_k) >=79:\n",
    "                        final_dict = {}\n",
    "                        final_dict[\"page\"] = pg_no\n",
    "                        final_dict[\"text\"] = text_instances['text']\n",
    "                        final_dict[\"bbox\"] = {\"x1\":text_instances['x0'],\n",
    "                                            \"y1\":text_instances['top'],\n",
    "                                            \"x2\":text_instances['x1'],\n",
    "                                            \"y2\":text_instances['bottom'],\n",
    "                                            \"width\":pages.width,\n",
    "                                            \"height\":pages.height\n",
    "                                            }\n",
    "                        final_dict[\"line_no\"] = item_val[1]\n",
    "                        final_result.append(final_dict)\n",
    "                        \n",
    "    return final_result, len(final_result)\n",
    "\n",
    "\n",
    "def get_missing_chapter_opener_bboxes(pdf, pdf_path):\n",
    "\n",
    "    unmatched_fuzzy,matched_fuzzy = extracted_table_of_contents(pdf)\n",
    "    results, unmatched_chapters_count = final_json_results_dumps(pdf_path,unmatched_fuzzy)\n",
    "    unmatched_chapters_json = return_json_result(results)\n",
    "\n",
    "    return unmatched_chapters_count, unmatched_chapters_json\n",
    "\n",
    "\n",
    "# pdf_path = '/data/copy_assessment_tool/modules/data/15031-4988-FullBook.pdf'\n",
    "# pdf = pdfplumber.open(pdf_path)\n",
    "\n",
    "# unmatched_chapters_count, unmatched_chapters_json = get_missing_chapter_opener_bboxes(pdf, pdf_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
